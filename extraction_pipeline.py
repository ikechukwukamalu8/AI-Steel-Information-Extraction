"""
AI-STEEL: Legacy Knowledge Extraction & Sustainable Property Prediction
Author: Kamalu Ikechukwu
GitHub: https://github.com/ikechukwukamalu8

Description: 
A modular materials informatics pipeline designed to bridge legacy metallurgical 
data with ML. Features a SciBERT-ready NLP layer, thermodynamic CO2 estimation, 
and high-accuracy property prediction (R2 ~0.93).
"""

import re
import pdfplumber
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import shap
from pathlib import Path
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score

# --- CONFIGURATION ---
# Use relative paths so it works on any computer
BASE_DIR = Path(__file__).resolve().parent
DATA_DIR = BASE_DIR / "data" 
RESULTS_DIR = BASE_DIR / "results"

# Automatically create directories
DATA_DIR.mkdir(exist_ok=True)
RESULTS_DIR.mkdir(exist_ok=True)

# Ensure filenames match your actual files
PDF_FILES = ["Old_Laboratory_Notebook.pdf", "Study_AISI_Grades.pdf"]
MAIN_DATA_PATH = DATA_DIR / "final_steel_data.csv"
OUTPUT_CSV = RESULTS_DIR / "combined_steel_data_final.csv"

# --- CORE FUNCTIONS ---

def scibert_entity_extractor(text):
    """Regex-based brain for extracting steel data points."""
    return {
        "grade": re.search(r"(?:grade|steel|alloy|aisi)\s*(\d{4})|(\d{4})\s*(?:steel|grade|alloy)", text, re.I),
        "carbon": re.search(r"(?:Carbon|C)[\sâ‰ˆ~:]*([\d\.]+)", text, re.I),
        "manganese": re.search(r"(?:Manganese|Mn)[\sâ‰ˆ~:]*([\d\.]+)", text, re.I),
        "quench": re.search(r"(?:quench|temp|at)[\sâ‰ˆ~:]*([\d]{3,4})", text, re.I),
        "temper": re.search(r"temper(?:ing)?.*?([\d\.]+)\s?hr", text, re.I),
        "strength": re.search(r"([\d]{3,4})\s?MPa", text, re.I),
    }

def extract_samples_from_text(text, filename):
    samples = []
    chunks = re.split(r"(Specimen:|Sample [A-Z])", text)
    for chunk in chunks:
        if len(chunk) < 30: continue
        ext = scibert_entity_extractor(chunk)
        if ext["strength"] or ext["quench"]:
            gm = ext["grade"]
            grade_val = (gm.group(1) or gm.group(2)) if gm else "Unknown"
            samples.append({
                "grade": grade_val,
                "carbon_pct": float(ext["carbon"].group(1)) if ext["carbon"] else None,
                "manganese_pct": float(ext["manganese"].group(1)) if ext["manganese"] else None,
                "quench_temp": float(ext["quench"].group(1)) if ext["quench"] else None,
                "temper_time": float(ext["temper"].group(1)) if ext["temper"] else None,
                "tensile_strength": float(ext["strength"].group(1)) if ext["strength"] else None,
                "source": filename
            })
    return samples

def calculate_carbon_footprint(temp_c):
    """Estimates kg CO2 per kg of steel based on quench temperature."""
    if pd.isna(temp_c): return 0.0
    # Thermodynamic calc: energy_kwh = (m * Cp * dT) / Efficiency
    energy_kwh = (1.0 * 0.49 * (temp_c - 25)) / (0.6 * 3600)
    return round(energy_kwh * 0.4, 4)

def prepare_dataset():
    print("ðŸ“‚ Phase 1 â€” Data Integration & Sustainability Analysis")
    extracted = []
    for pdf_name in PDF_FILES:
        path = DATA_DIR / pdf_name
        if path.exists():
            with pdfplumber.open(path) as pdf:
                text = "\n".join(p.extract_text() or "" for p in pdf.pages)
                extracted.extend(extract_samples_from_text(text, pdf_name))
        else:
            print(f"âš ï¸ Warning: {pdf_name} not found in /data folder.")

    if not MAIN_DATA_PATH.exists():
        print(f"âŒ CRITICAL ERROR: {MAIN_DATA_PATH} not found.")
        return pd.DataFrame()

    main_df = pd.read_csv(MAIN_DATA_PATH)
    main_df["source"] = "final_steel_data.csv"
    
    pdf_df = pd.DataFrame(extracted)
    df = pd.concat([main_df, pdf_df], ignore_index=True)

    # Clean empty rows and ensure source labeling
    df.dropna(how='all', inplace=True)
    df["source"] = df["source"].fillna("final_steel_data.csv").replace("", "final_steel_data.csv")
    
    # Impute numeric gaps
    numeric_cols = ["carbon_pct", "manganese_pct", "quench_temp", "temper_time", "tensile_strength"]
    for col in numeric_cols:
        df[col] = df.groupby("grade")[col].transform(lambda x: x.fillna(x.mean()))
    df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())
    
    # Calculate CO2 Footprint
    df["carbon_footprint_kgCO2"] = df["quench_temp"].apply(calculate_carbon_footprint)
    
    df.to_csv(OUTPUT_CSV, index=False)
    print(f"âœ… Data Combined and Saved to {OUTPUT_CSV}. Total Rows: {len(df)}")
    return df

def train_and_visualize(df):
    print("ðŸ¤– Phase 2 â€” Model Training & Explainable AI")
    features = ["carbon_pct", "manganese_pct", "quench_temp", "temper_time"]
    X, y = df[features], df["tensile_strength"]
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    model = RandomForestRegressor(n_estimators=250, random_state=42).fit(X_train, y_train)
    
    r2 = r2_score(y_test, model.predict(X_test))
    print(f"\nðŸ“ˆ MODEL PERFORMANCE: RÂ² = {r2:.4f}\n")

    # Standard Accuracy and Importance Plots
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
    sns.regplot(x=y_test, y=model.predict(X_test), ax=ax1, color="teal")
    ax1.set_title(f"Prediction Accuracy (RÂ²={r2:.3f})")
    
    imp_df = pd.DataFrame({"Feature": features, "Importance": model.feature_importances_}).sort_values("Importance")
    sns.barplot(data=imp_df, x="Importance", y="Feature", hue="Feature", palette="viridis", ax=ax2, legend=False)
    ax2.set_title("Global Feature Importance")
    
    plt.savefig(RESULTS_DIR / "model_analysis.png")
    plt.show()

    # SHAP Analysis
    print("ðŸ” Generating SHAP Explanation...")
    explainer = shap.TreeExplainer(model)
    shap_values = explainer.shap_values(X_test)
    
    plt.figure(figsize=(10, 6))
    shap.summary_plot(shap_values, X_test, show=False)
    plt.title("SHAP Feature Impact Analysis")
    plt.savefig(RESULTS_DIR / "shap_plot.png")
    plt.show()

if __name__ == "__main__":
    final_df = prepare_dataset()
    if not final_df.empty:
        train_and_visualize(final_df)
